{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci Neuronowe - Laboratorium 4. Wybór funkcji kosztu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja czy klasyfikacja?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Regresja - błąd średniokwadratowy\n",
    "Przyjmijmy, że mamy regresję jednowymiarową (wtedy $f(X_i|\\theta), Y_i \\in \\mathbb{R}$) lub wielowymiarową (wtedy $f(X_i|\\theta), Y_i \\in \\mathbb{R}^m$)\n",
    "$$\n",
    "\\mathcal{L}(\\theta| X, Y) = \\tfrac{1}{N} \\sum_{i=1}^N \\| f(X_i|\\theta) - Y_i \\|_2^2 \n",
    "$$\n",
    "\n",
    "\n",
    "    theanets.Regresor\n",
    "\n",
    "\n",
    "#### Klasyfikacja - błąd entropii krzyżowej (błąd logistyczny)\n",
    "Przyjmijmy że mamy `m` klas i `m` neuronów wyjściowych gora -> wyjscie neuronu maksymalizujemy po wszystkich wyjsciach neuronow wyjsciowych stricte klasyfikacja\n",
    "$$\n",
    "\\mathcal{L}(\\theta| X, Y) = \\tfrac{1}{N} \\sum_{i=1}^N -\\log \\frac{\\exp(f_{Y_i}(X_i|\\theta))}{\\sum_{k=1}^m \\exp(f_k(X_i|\\theta))}\n",
    "$$\n",
    "\n",
    "    theanets.Classifer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytania do dyskusji:\n",
    "\n",
    "* Dlaczego te dwie funkcje kosztu są najbardziej popularne?\n",
    "* Czy patrząc na nie przychodzi wam na myśl jakaś prosta inna funkcja kosztu? Jaka? Jakie miałaby cechy?\n",
    "* Jaka jest różnica pomiędzy tymi kosztami? W ogólności? A dla problemu binarnego?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadania\n",
    "\n",
    "Stwórz trzy architektury i przetestuj je w problemie rozpoznawania pisma:\n",
    "\n",
    "* Model regresji z jednym neuronem wyjściowem\n",
    "* Model regresji z `m` neuronami wyjściowymi (kodowanie klas one-hot-encoding)\n",
    "* Model klasyfikacji  z `m` neuronami wyjściowymi (kodowanie klas one-hot-encoding)\n",
    "\n",
    "1) dokonczyc\n",
    "2) przyjrzyj sie projektowi 2 i koncowemu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza procesu uczenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy użyciu `theanets` oraz naszego zbioru danych (możesz zredukować go do mniejszej liczby przykładów żeby zwiększyć szybkość działania) przeprowadź eksperyment, w którym po każdej iteracji procesu uczenia sieci neuronowej sprawdzasz jaki wynik osiąga ona na zbiorze uczącym oraz jaki na zbiorze testującym. Zaprezentuj wynik tego eksperymentu w postaci wykresów (zależności czasu od accuracy). Najlepiej twórz wykres co określoną liczbę iteracji żeby powstawał on na bieżąco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:67: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/theanets/main.py:128: DeprecationWarning: please use --hidden-activation instead of --activation\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400) (5000, 1)\n",
      "(2500, 400) (2500, 400) (2500, 1) (2500, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import theanets\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "D = loadmat('data/ex3data1.mat')\n",
    "X, y = D['X'], D['y']\n",
    "\n",
    "\n",
    "#y=y.ravel() # y musi być wektorem, a nie macierzą (5000, 1)\n",
    "#y = y.reshape(y.shape[0],1)\n",
    "y[y == 10] = 0\n",
    "print X.shape, y.shape\n",
    "\n",
    "a_train, a_test, b_train, b_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "x = X[0]\n",
    "#b = b_train.ravel()\n",
    "#print a_train.shape[1]\n",
    "exp = theanets.Experiment(\n",
    "#    theanets.recurrent.Regressor,\n",
    "#     layers=(a_train.shape[1], \n",
    "#             10, \n",
    "#             10)\n",
    "#     )\n",
    "theanets.feedforward.Regressor,\n",
    "                    layers=(400,10,1),\n",
    "                    optimize='sgd',\n",
    "                    activation='tanh')\n",
    "\n",
    "print a_train.shape, a_test.shape, b_train.shape, b_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "for iters, (train, valid) in enumerate(exp.itertrain((a_train, b_train), optimize='sgd', \n",
    "                                                    learning_rate=0.1, momentum=0.1,\n",
    "                                                    patience=1)):\n",
    "        print iters\n",
    "        tr = 1.0 - accuracy_score(b_train, exp.network.predict(a_train).astype(int), normalize=True)\n",
    "        te = 1.0 - accuracy_score(b_test, exp.network.predict(a_test).astype(int), normalize=True)\n",
    "        print iters, \"error on training set: %7.4f\" % tr\n",
    "        print iters, \"error on testing set: %7.4f\" % te\n",
    "        plt.figure()\n",
    "        d.append(tr)\n",
    "        plt.plot(d)\n",
    "        plt.savefig('wyk.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytania analityczne / do dyskusji\n",
    "\n",
    "* Co się dzieje gdy zmienisz wielkość warstwy ukrytej na np. `10`? A jeśli na `2000`? \n",
    "* Jak wyglądają te wykresy dla modeli regresji i klasyfikacji? \n",
    "* Skąd takie zależności? \n",
    "* Czy potrafisz wydzielić jakieś sekcje w obserwowanych wykresach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "216 error on training set:  0.0312\n",
    "216 error on testing set:  0.0940 neurony 10 w warstwie ukrytej\n",
    "warstwa 200, strasznie dlugo liczy i jakby szybciej zbiega przy 60 iteracji mam juz 0.08 i  0.10 i na trenujacym wiekszy\n",
    "blad, ale mniejsza roznica wzgledem testujacego:\n",
    "216 error on training set:  0.0312\n",
    "216 error on testing set:  0.0896\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykładowe rezultaty\n",
    "\n",
    "\n",
    "#### Regresja 10 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/10reg.png\" width=\"600\">\n",
    "\n",
    "#### Klasyfikacja 10 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/10cla.png\" width=\"600\">\n",
    "\n",
    "#### Regresja 100 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/100reg.png\" width=\"600\">\n",
    "\n",
    "#### Klasyfikacja 100 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/100cla.png\" width=\"600\">\n",
    "\n",
    "#### Regresja 1000 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/1000reg.png\" width=\"600\">\n",
    "\n",
    "#### Klasyfikacja 1000 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/1000cla.png\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

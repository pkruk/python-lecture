{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci Neuronowe - Laboratorium 4. Wybór funkcji kosztu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja czy klasyfikacja?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Regresja - błąd średniokwadratowy\n",
    "Przyjmijmy, że mamy regresję jednowymiarową (wtedy $f(X_i|\\theta), Y_i \\in \\mathbb{R}$) lub wielowymiarową (wtedy $f(X_i|\\theta), Y_i \\in \\mathbb{R}^m$)\n",
    "$$\n",
    "\\mathcal{L}(\\theta| X, Y) = \\tfrac{1}{N} \\sum_{i=1}^N \\| f(X_i|\\theta) - Y_i \\|_2^2 \n",
    "$$\n",
    "\n",
    "\n",
    "    theanets.Regresor\n",
    "\n",
    "\n",
    "#### Klasyfikacja - błąd entropii krzyżowej (błąd logistyczny)\n",
    "Przyjmijmy że mamy `m` klas i `m` neuronów wyjściowych gora -> wyjscie neuronu maksymalizujemy po wszystkich wyjsciach neuronow wyjsciowych stricte klasyfikacja\n",
    "$$\n",
    "\\mathcal{L}(\\theta| X, Y) = \\tfrac{1}{N} \\sum_{i=1}^N -\\log \\frac{\\exp(f_{Y_i}(X_i|\\theta))}{\\sum_{k=1}^m \\exp(f_k(X_i|\\theta))}\n",
    "$$\n",
    "\n",
    "    theanets.Classifer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytania do dyskusji:\n",
    "\n",
    "* Dlaczego te dwie funkcje kosztu są najbardziej popularne?\n",
    "* Czy patrząc na nie przychodzi wam na myśl jakaś prosta inna funkcja kosztu? Jaka? Jakie miałaby cechy?\n",
    "* Jaka jest różnica pomiędzy tymi kosztami? W ogólności? A dla problemu binarnego?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadania\n",
    "\n",
    "Stwórz trzy architektury i przetestuj je w problemie rozpoznawania pisma:\n",
    "\n",
    "* Model regresji z jednym neuronem wyjściowem\n",
    "* Model regresji z `m` neuronami wyjściowymi (kodowanie klas one-hot-encoding)\n",
    "* Model klasyfikacji  z `m` neuronami wyjściowymi (kodowanie klas one-hot-encoding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza procesu uczenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy użyciu `theanets` oraz naszego zbioru danych (możesz zredukować go do mniejszej liczby przykładów żeby zwiększyć szybkość działania) przeprowadź eksperyment, w którym po każdej iteracji procesu uczenia sieci neuronowej sprawdzasz jaki wynik osiąga ona na zbiorze uczącym oraz jaki na zbiorze testującym. Zaprezentuj wynik tego eksperymentu w postaci wykresów (zależności czasu od accuracy). Najlepiej twórz wykres co określoną liczbę iteracji żeby powstawał on na bieżąco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:67: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/theanets/main.py:128: DeprecationWarning: please use --hidden-activation instead of --activation\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400) (5000, 1)\n",
      "[[3]\n",
      " [4]\n",
      " [5]\n",
      " ..., \n",
      " [7]\n",
      " [2]\n",
      " [2]]\n",
      "0\n",
      "0 error on training set: -472.0000\n",
      "0 error on testing set: -527.0000\n",
      "1\n",
      "1 error on training set: -758.0000\n",
      "1 error on testing set: -715.0000\n",
      "2\n",
      "2 error on training set: -979.0000\n",
      "2 error on testing set: -947.0000\n",
      "3\n",
      "3 error on training set: -1052.0000\n",
      "3 error on testing set: -972.0000\n",
      "4\n",
      "4 error on training set: -908.0000\n",
      "4 error on testing set: -872.0000\n",
      "5\n",
      "5 error on training set: -1134.0000\n",
      "5 error on testing set: -1104.0000\n",
      "6\n",
      "6 error on training set: -1046.0000\n",
      "6 error on testing set: -984.0000\n",
      "7\n",
      "7 error on training set: -1076.0000\n",
      "7 error on testing set: -992.0000\n",
      "8\n",
      "8 error on training set: -928.0000\n",
      "8 error on testing set: -908.0000\n",
      "9\n",
      "9 error on training set: -1202.0000\n",
      "9 error on testing set: -1087.0000\n",
      "10\n",
      "10 error on training set: -541.0000\n",
      "10 error on testing set: -536.0000\n",
      "11\n",
      "11 error on training set: -901.0000\n",
      "11 error on testing set: -877.0000\n",
      "12\n",
      "12 error on training set: -1292.0000\n",
      "12 error on testing set: -1141.0000\n",
      "13\n",
      "13 error on training set: -1282.0000\n",
      "13 error on testing set: -1205.0000\n",
      "14\n",
      "14 error on training set: -1418.0000\n",
      "14 error on testing set: -1296.0000\n",
      "15\n",
      "15 error on training set: -1218.0000\n",
      "15 error on testing set: -1141.0000\n",
      "16\n",
      "16 error on training set: -893.0000\n",
      "16 error on testing set: -920.0000\n",
      "17\n",
      "17 error on training set: -937.0000\n",
      "17 error on testing set: -897.0000\n",
      "18\n",
      "18 error on training set: -1273.0000\n",
      "18 error on testing set: -1170.0000\n",
      "19\n",
      "19 error on training set: -748.0000\n",
      "19 error on testing set: -735.0000\n",
      "20\n",
      "20 error on training set: -1234.0000\n",
      "20 error on testing set: -1167.0000\n",
      "21\n",
      "21 error on training set: -596.0000\n",
      "21 error on testing set: -622.0000\n",
      "22\n",
      "22 error on training set: -972.0000\n",
      "22 error on testing set: -986.0000\n",
      "23\n",
      "23 error on training set: -805.0000\n",
      "23 error on testing set: -812.0000\n",
      "24\n",
      "24 error on training set: -1186.0000\n",
      "24 error on testing set: -1130.0000\n",
      "25\n",
      "25 error on training set: -602.0000\n",
      "25 error on testing set: -609.0000\n",
      "26\n",
      "26 error on training set: -758.0000\n",
      "26 error on testing set: -726.0000\n",
      "27\n",
      "27 error on training set: -1581.0000\n",
      "27 error on testing set: -1376.0000\n",
      "28\n",
      "28 error on training set: -1422.0000\n",
      "28 error on testing set: -1216.0000\n",
      "29\n",
      "29 error on training set: -1273.0000\n",
      "29 error on testing set: -1129.0000\n",
      "30\n",
      "30 error on training set: -862.0000\n",
      "30 error on testing set: -819.0000\n",
      "31\n",
      "31 error on training set: -974.0000\n",
      "31 error on testing set: -881.0000\n",
      "32\n",
      "32 error on training set: -872.0000\n",
      "32 error on testing set: -853.0000\n",
      "33\n",
      "33 error on training set: -1597.0000\n",
      "33 error on testing set: -1386.0000\n",
      "34\n",
      "34 error on training set: -511.0000\n",
      "34 error on testing set: -592.0000\n",
      "35\n",
      "35 error on training set: -715.0000\n",
      "35 error on testing set: -712.0000\n",
      "36\n",
      "36 error on training set: -1189.0000\n",
      "36 error on testing set: -1054.0000\n",
      "37\n",
      "37 error on training set: -1606.0000\n",
      "37 error on testing set: -1377.0000\n",
      "38\n",
      "38 error on training set: -738.0000\n",
      "38 error on testing set: -746.0000\n",
      "39\n",
      "39 error on training set: -805.0000\n",
      "39 error on testing set: -760.0000\n",
      "40\n",
      "40 error on training set: -852.0000\n",
      "40 error on testing set: -818.0000\n",
      "41\n",
      "41 error on training set: -994.0000\n",
      "41 error on testing set: -902.0000\n",
      "42\n",
      "42 error on training set: -1262.0000\n",
      "42 error on testing set: -1103.0000\n",
      "43\n",
      "43 error on training set: -1607.0000\n",
      "43 error on testing set: -1340.0000\n",
      "44\n",
      "44 error on training set: -1035.0000\n",
      "44 error on testing set: -871.0000\n",
      "45\n",
      "45 error on training set: -707.0000\n",
      "45 error on testing set: -696.0000\n",
      "46\n",
      "46 error on training set: -1481.0000\n",
      "46 error on testing set: -1229.0000\n",
      "47\n",
      "47 error on training set: -1050.0000\n",
      "47 error on testing set: -907.0000\n",
      "48\n",
      "48 error on training set: -1608.0000\n",
      "48 error on testing set: -1389.0000\n",
      "49\n",
      "49 error on training set: -895.0000\n",
      "49 error on testing set: -828.0000\n",
      "50\n",
      "50 error on training set: -925.0000\n",
      "50 error on testing set: -849.0000\n",
      "51\n",
      "51 error on training set: -1500.0000\n",
      "51 error on testing set: -1217.0000\n",
      "52\n",
      "52 error on training set: -1407.0000\n",
      "52 error on testing set: -1208.0000\n",
      "53\n",
      "53 error on training set: -1107.0000\n",
      "53 error on testing set: -924.0000\n",
      "54\n",
      "54 error on training set: -1082.0000\n",
      "54 error on testing set: -937.0000\n",
      "55\n",
      "55 error on training set: -1233.0000\n",
      "55 error on testing set: -1042.0000\n",
      "56\n",
      "56 error on training set: -642.0000\n",
      "56 error on testing set: -666.0000\n",
      "57\n",
      "57 error on training set: -1047.0000\n",
      "57 error on testing set: -893.0000\n",
      "58\n",
      "58 error on training set: -1074.0000\n",
      "58 error on testing set: -980.0000\n",
      "59\n",
      "59 error on training set: -1244.0000\n",
      "59 error on testing set: -1047.0000\n",
      "60\n",
      "60 error on training set: -944.0000\n",
      "60 error on testing set: -842.0000\n",
      "61\n",
      "61 error on training set: -1284.0000\n",
      "61 error on testing set: -1102.0000\n",
      "62\n",
      "62 error on training set: -797.0000\n",
      "62 error on testing set: -774.0000\n",
      "63\n",
      "63 error on training set: -850.0000\n",
      "63 error on testing set: -768.0000\n",
      "64\n",
      "64 error on training set: -1667.0000\n",
      "64 error on testing set: -1378.0000\n",
      "65\n",
      "65 error on training set: -954.0000\n",
      "65 error on testing set: -848.0000\n",
      "66\n",
      "66 error on training set: -1212.0000\n",
      "66 error on testing set: -987.0000\n",
      "67\n",
      "67 error on training set: -1216.0000\n",
      "67 error on testing set: -1037.0000\n",
      "68\n",
      "68 error on training set: -798.0000\n",
      "68 error on testing set: -783.0000\n",
      "69\n",
      "69 error on training set: -832.0000\n",
      "69 error on testing set: -778.0000\n",
      "70\n",
      "70 error on training set: -1708.0000\n",
      "70 error on testing set: -1384.0000\n",
      "71\n",
      "71 error on training set: -618.0000\n",
      "71 error on testing set: -658.0000\n",
      "72\n",
      "72 error on training set: -1095.0000\n",
      "72 error on testing set: -954.0000\n",
      "73\n",
      "73 error on training set: -1662.0000\n",
      "73 error on testing set: -1379.0000\n",
      "74\n",
      "74 error on training set: -1596.0000\n",
      "74 error on testing set: -1270.0000\n",
      "75\n",
      "75 error on training set: -1057.0000\n",
      "75 error on testing set: -933.0000\n",
      "76\n",
      "76 error on training set: -1194.0000\n",
      "76 error on testing set: -1001.0000\n",
      "77\n",
      "77 error on training set: -885.0000\n",
      "77 error on testing set: -801.0000\n",
      "78\n",
      "78 error on training set: -1745.0000\n",
      "78 error on testing set: -1441.0000\n",
      "79\n",
      "79 error on training set: -1225.0000\n",
      "79 error on testing set: -1040.0000\n",
      "80\n",
      "80 error on training set: -1354.0000\n",
      "80 error on testing set: -1054.0000\n",
      "81\n",
      "81 error on training set: -1758.0000\n",
      "81 error on testing set: -1427.0000\n",
      "82\n",
      "82 error on training set: -1368.0000\n",
      "82 error on testing set: -1151.0000\n",
      "83\n",
      "83 error on training set: -1205.0000\n",
      "83 error on testing set: -965.0000\n",
      "84\n",
      "84 error on training set: -1311.0000\n",
      "84 error on testing set: -1086.0000\n",
      "85\n",
      "85 error on training set: -1645.0000\n",
      "85 error on testing set: -1350.0000\n",
      "86\n",
      "86 error on training set: -1027.0000\n",
      "86 error on testing set: -883.0000\n",
      "87\n",
      "87 error on training set: -1570.0000\n",
      "87 error on testing set: -1293.0000\n",
      "88\n",
      "88 error on training set: -754.0000\n",
      "88 error on testing set: -733.0000\n",
      "89\n",
      "89 error on training set: -1078.0000\n",
      "89 error on testing set: -898.0000\n",
      "90\n",
      "90 error on training set: -945.0000\n",
      "90 error on testing set: -841.0000\n",
      "91\n",
      "91 error on training set: -1314.0000\n",
      "91 error on testing set: -1098.0000\n",
      "92\n",
      "92 error on training set: -953.0000\n",
      "92 error on testing set: -830.0000\n",
      "93\n",
      "93 error on training set: -848.0000\n",
      "93 error on testing set: -785.0000\n",
      "94\n",
      "94 error on training set: -1729.0000\n",
      "94 error on testing set: -1396.0000\n",
      "95\n",
      "95 error on training set: -957.0000\n",
      "95 error on testing set: -873.0000\n",
      "96\n",
      "96 error on training set: -842.0000\n",
      "96 error on testing set: -778.0000\n",
      "97\n",
      "97 error on training set: -1491.0000\n",
      "97 error on testing set: -1213.0000\n",
      "98\n",
      "98 error on training set: -1087.0000\n",
      "98 error on testing set: -961.0000\n",
      "99\n",
      "99 error on training set: -1038.0000\n",
      "99 error on testing set: -866.0000\n",
      "100\n",
      "100 error on training set: -859.0000\n",
      "100 error on testing set: -785.0000\n",
      "101\n",
      "101 error on training set: -1258.0000\n",
      "101 error on testing set: -1011.0000\n",
      "102\n",
      "102 error on training set: -899.0000\n",
      "102 error on testing set: -803.0000\n",
      "103\n",
      "103 error on training set: -916.0000\n",
      "103 error on testing set: -829.0000\n",
      "104\n",
      "104 error on training set: -783.0000\n",
      "104 error on testing set: -743.0000\n",
      "105\n",
      "105 error on training set: -743.0000\n",
      "105 error on testing set: -745.0000\n",
      "106\n",
      "106 error on training set: -866.0000\n",
      "106 error on testing set: -763.0000\n",
      "107\n",
      "107 error on training set: -954.0000\n",
      "107 error on testing set: -831.0000\n",
      "108\n",
      "108 error on training set: -757.0000\n",
      "108 error on testing set: -727.0000\n",
      "109\n",
      "109 error on training set: -992.0000\n",
      "109 error on testing set: -823.0000\n",
      "110\n",
      "110 error on training set: -1060.0000\n",
      "110 error on testing set: -889.0000\n",
      "111\n",
      "111 error on training set: -1288.0000\n",
      "111 error on testing set: -1068.0000\n",
      "112\n",
      "112 error on training set: -855.0000\n",
      "112 error on testing set: -767.0000\n",
      "113\n",
      "113 error on training set: -1201.0000\n",
      "113 error on testing set: -1017.0000\n",
      "114\n",
      "114 error on training set: -1724.0000\n",
      "114 error on testing set: -1391.0000\n",
      "115\n",
      "115 error on training set: -812.0000\n",
      "115 error on testing set: -756.0000\n",
      "116\n",
      "116 error on training set: -1557.0000\n",
      "116 error on testing set: -1273.0000\n",
      "117\n",
      "117 error on training set: -785.0000\n",
      "117 error on testing set: -726.0000\n",
      "118\n",
      "118 error on training set: -1055.0000\n",
      "118 error on testing set: -883.0000\n",
      "119\n",
      "119 error on training set: -1200.0000\n",
      "119 error on testing set: -971.0000\n",
      "120\n",
      "120 error on training set: -1102.0000\n",
      "120 error on testing set: -904.0000\n",
      "121\n",
      "121 error on training set: -1534.0000\n",
      "121 error on testing set: -1219.0000\n",
      "122\n",
      "122 error on training set: -694.0000\n",
      "122 error on testing set: -719.0000\n",
      "123\n",
      "123 error on training set: -1660.0000\n",
      "123 error on testing set: -1314.0000\n",
      "124\n",
      "124 error on training set: -1394.0000\n",
      "124 error on testing set: -1105.0000\n",
      "125\n",
      "125 error on training set: -941.0000\n",
      "125 error on testing set: -827.0000\n",
      "126\n",
      "126 error on training set: -1265.0000\n",
      "126 error on testing set: -985.0000\n",
      "127\n",
      "127 error on training set: -1225.0000\n",
      "127 error on testing set: -971.0000\n",
      "128\n",
      "128 error on training set: -1126.0000\n",
      "128 error on testing set: -936.0000\n",
      "129\n",
      "129 error on training set: -507.0000\n",
      "129 error on testing set: -576.0000\n",
      "130\n",
      "130 error on training set: -841.0000\n",
      "130 error on testing set: -767.0000\n",
      "131\n",
      "131 error on training set: -1014.0000\n",
      "131 error on testing set: -854.0000\n",
      "132\n",
      "132 error on training set: -942.0000\n",
      "132 error on testing set: -809.0000\n",
      "133\n",
      "133 error on training set: -1522.0000\n",
      "133 error on testing set: -1208.0000\n",
      "134\n",
      "134 error on training set: -1475.0000\n",
      "134 error on testing set: -1145.0000\n",
      "135\n",
      "135 error on training set: -998.0000\n",
      "135 error on testing set: -849.0000\n",
      "136\n",
      "136 error on training set: -1720.0000\n",
      "136 error on testing set: -1361.0000\n",
      "137\n",
      "137 error on training set: -1104.0000\n",
      "137 error on testing set: -888.0000\n",
      "138\n",
      "138 error on training set: -1169.0000\n",
      "138 error on testing set: -935.0000\n",
      "139\n",
      "139 error on training set: -1570.0000\n",
      "139 error on testing set: -1218.0000\n",
      "140\n",
      "140 error on training set: -1474.0000\n",
      "140 error on testing set: -1150.0000\n",
      "141\n",
      "141 error on training set: -1549.0000\n",
      "141 error on testing set: -1186.0000\n",
      "142\n",
      "142 error on training set: -976.0000\n",
      "142 error on testing set: -827.0000\n",
      "143\n",
      "143 error on training set: -1075.0000\n",
      "143 error on testing set: -898.0000\n",
      "144\n",
      "144 error on training set: -1352.0000\n",
      "144 error on testing set: -1046.0000\n",
      "145\n",
      "145 error on training set: -867.0000\n",
      "145 error on testing set: -766.0000\n",
      "146\n",
      "146 error on training set: -1481.0000\n",
      "146 error on testing set: -1115.0000\n",
      "147\n",
      "147 error on training set: -1553.0000\n",
      "147 error on testing set: -1162.0000\n",
      "148\n",
      "148 error on training set: -847.0000\n",
      "148 error on testing set: -767.0000\n",
      "149\n",
      "149 error on training set: -1146.0000\n",
      "149 error on testing set: -928.0000\n",
      "150\n",
      "150 error on training set: -1629.0000\n",
      "150 error on testing set: -1227.0000\n",
      "151\n",
      "151 error on training set: -1424.0000\n",
      "151 error on testing set: -1115.0000\n",
      "152\n",
      "152 error on training set: -756.0000\n",
      "152 error on testing set: -716.0000\n",
      "153\n",
      "153 error on training set: -983.0000\n",
      "153 error on testing set: -814.0000\n",
      "154\n",
      "154 error on training set: -1600.0000\n",
      "154 error on testing set: -1237.0000\n",
      "155\n",
      "155 error on training set: -1600.0000\n",
      "155 error on testing set: -1216.0000\n",
      "156\n",
      "156 error on training set: -638.0000\n",
      "156 error on testing set: -673.0000\n",
      "157\n",
      "157 error on training set: -885.0000\n",
      "157 error on testing set: -791.0000\n",
      "158\n",
      "158 error on training set: -1258.0000\n",
      "158 error on testing set: -935.0000\n",
      "159\n",
      "159 error on training set: -1616.0000\n",
      "159 error on testing set: -1246.0000\n",
      "160\n",
      "160 error on training set: -986.0000\n",
      "160 error on testing set: -807.0000\n",
      "161\n",
      "161 error on training set: -1021.0000\n",
      "161 error on testing set: -841.0000\n",
      "162\n",
      "162 error on training set: -951.0000\n",
      "162 error on testing set: -804.0000\n",
      "163\n",
      "163 error on training set: -1029.0000\n",
      "163 error on testing set: -830.0000\n",
      "164\n",
      "164 error on training set: -1399.0000\n",
      "164 error on testing set: -1122.0000\n",
      "165\n",
      "165 error on training set: -1528.0000\n",
      "165 error on testing set: -1198.0000\n",
      "166\n",
      "166 error on training set: -780.0000\n",
      "166 error on testing set: -751.0000\n",
      "167\n",
      "167 error on training set: -1101.0000\n",
      "167 error on testing set: -897.0000\n",
      "168\n",
      "168 error on training set: -998.0000\n",
      "168 error on testing set: -842.0000\n",
      "169\n",
      "169 error on training set: -1212.0000\n",
      "169 error on testing set: -935.0000\n",
      "170\n",
      "170 error on training set: -1658.0000\n",
      "170 error on testing set: -1174.0000\n",
      "171\n",
      "171 error on training set: -1384.0000\n",
      "171 error on testing set: -977.0000\n",
      "172\n",
      "172 error on training set: -647.0000\n",
      "172 error on testing set: -655.0000\n",
      "173\n",
      "173 error on training set: -1366.0000\n",
      "173 error on testing set: -984.0000\n",
      "174\n",
      "174 error on training set: -682.0000\n",
      "174 error on testing set: -687.0000\n",
      "175\n",
      "175 error on training set: -1541.0000\n",
      "175 error on testing set: -1149.0000\n",
      "176\n",
      "176 error on training set: -1138.0000\n",
      "176 error on testing set: -856.0000\n",
      "177\n",
      "177 error on training set: -955.0000\n",
      "177 error on testing set: -799.0000\n",
      "178\n",
      "178 error on training set: -1078.0000\n",
      "178 error on testing set: -851.0000\n",
      "179\n",
      "179 error on training set: -897.0000\n",
      "179 error on testing set: -795.0000\n",
      "180\n",
      "180 error on training set: -1348.0000\n",
      "180 error on testing set: -994.0000\n",
      "181\n",
      "181 error on training set: -915.0000\n",
      "181 error on testing set: -771.0000\n",
      "182\n",
      "182 error on training set: -966.0000\n",
      "182 error on testing set: -820.0000\n",
      "183\n",
      "183 error on training set: -1367.0000\n",
      "183 error on testing set: -1032.0000\n",
      "184\n",
      "184 error on training set: -1776.0000\n",
      "184 error on testing set: -1226.0000\n",
      "185\n",
      "185 error on training set: -936.0000\n",
      "185 error on testing set: -793.0000\n",
      "186\n",
      "186 error on training set: -1168.0000\n",
      "186 error on testing set: -901.0000\n",
      "187\n",
      "187 error on training set: -1573.0000\n",
      "187 error on testing set: -1120.0000\n",
      "188\n",
      "188 error on training set: -1269.0000\n",
      "188 error on testing set: -912.0000\n",
      "189\n",
      "189 error on training set: -1685.0000\n",
      "189 error on testing set: -1220.0000\n",
      "190\n",
      "190 error on training set: -777.0000\n",
      "190 error on testing set: -740.0000\n",
      "191\n",
      "191 error on training set: -1433.0000\n",
      "191 error on testing set: -1054.0000\n",
      "192\n",
      "192 error on training set: -913.0000\n",
      "192 error on testing set: -786.0000\n",
      "193\n",
      "193 error on training set: -740.0000\n",
      "193 error on testing set: -734.0000\n",
      "194\n",
      "194 error on training set: -1076.0000\n",
      "194 error on testing set: -861.0000\n",
      "195\n",
      "195 error on training set: -861.0000\n",
      "195 error on testing set: -765.0000\n",
      "196\n",
      "196 error on training set: -809.0000\n",
      "196 error on testing set: -770.0000\n",
      "197\n",
      "197 error on training set: -604.0000\n",
      "197 error on testing set: -652.0000\n",
      "198\n",
      "198 error on training set: -1470.0000\n",
      "198 error on testing set: -1083.0000\n",
      "199\n",
      "199 error on training set: -1220.0000\n",
      "199 error on testing set: -907.0000\n",
      "200\n",
      "200 error on training set: -920.0000\n",
      "200 error on testing set: -797.0000\n",
      "201\n",
      "201 error on training set: -1613.0000\n",
      "201 error on testing set: -1218.0000\n",
      "202\n",
      "202 error on training set: -896.0000\n",
      "202 error on testing set: -778.0000\n",
      "203\n",
      "203 error on training set: -1037.0000\n",
      "203 error on testing set: -822.0000\n",
      "204\n",
      "204 error on training set: -893.0000\n",
      "204 error on testing set: -805.0000\n",
      "205\n",
      "205 error on training set: -749.0000\n",
      "205 error on testing set: -695.0000\n",
      "206\n",
      "206 error on training set: -1131.0000\n",
      "206 error on testing set: -859.0000\n",
      "207\n",
      "207 error on training set: -1443.0000\n",
      "207 error on testing set: -1040.0000\n",
      "208\n",
      "208 error on training set: -961.0000\n",
      "208 error on testing set: -806.0000\n",
      "209\n",
      "209 error on training set: -1077.0000\n",
      "209 error on testing set: -834.0000\n",
      "210\n",
      "210 error on training set: -1317.0000\n",
      "210 error on testing set: -997.0000\n",
      "211\n",
      "211 error on training set: -1022.0000\n",
      "211 error on testing set: -837.0000\n",
      "212\n",
      "212 error on training set: -1021.0000\n",
      "212 error on testing set: -853.0000\n",
      "213\n",
      "213 error on training set: -1843.0000\n",
      "213 error on testing set: -1310.0000\n",
      "214\n",
      "214 error on training set: -715.0000\n",
      "214 error on testing set: -706.0000\n",
      "215\n",
      "215 error on training set: -1139.0000\n",
      "215 error on testing set: -879.0000\n",
      "216\n",
      "216 error on training set: -772.0000\n",
      "216 error on testing set: -727.0000\n",
      "217\n",
      "217 error on training set: -1767.0000\n",
      "217 error on testing set: -1227.0000\n",
      "218\n",
      "218 error on training set: -793.0000\n",
      "218 error on testing set: -745.0000\n",
      "219\n",
      "219 error on training set: -1294.0000\n",
      "219 error on testing set: -1007.0000\n",
      "220\n",
      "220 error on training set: -935.0000\n",
      "220 error on testing set: -795.0000\n",
      "221\n",
      "221 error on training set: -1498.0000\n",
      "221 error on testing set: -1075.0000\n",
      "222\n",
      "222 error on training set: -1035.0000\n",
      "222 error on testing set: -811.0000\n",
      "223\n",
      "223 error on training set: -1025.0000\n",
      "223 error on testing set: -813.0000\n",
      "224\n",
      "224 error on training set: -1109.0000\n",
      "224 error on testing set: -846.0000\n",
      "225\n",
      "225 error on training set: -1525.0000\n",
      "225 error on testing set: -1093.0000\n",
      "226\n",
      "226 error on training set: -955.0000\n",
      "226 error on testing set: -789.0000\n",
      "227\n",
      "227 error on training set: -1043.0000\n",
      "227 error on testing set: -873.0000\n",
      "228\n",
      "228 error on training set: -1252.0000\n",
      "228 error on testing set: -886.0000\n",
      "229\n",
      "229 error on training set: -886.0000\n",
      "229 error on testing set: -768.0000\n",
      "230\n",
      "230 error on training set: -832.0000\n",
      "230 error on testing set: -748.0000\n",
      "231\n",
      "231 error on training set: -1103.0000\n",
      "231 error on testing set: -881.0000\n",
      "232\n",
      "232 error on training set: -638.0000\n",
      "232 error on testing set: -665.0000\n",
      "233\n",
      "233 error on training set: -1135.0000\n",
      "233 error on testing set: -896.0000\n",
      "234\n",
      "234 error on training set: -1570.0000\n",
      "234 error on testing set: -1193.0000\n",
      "235\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ca8e9742457a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m#print exp.network.predict(a_train).astype(int)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mte\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"error on training set: %7.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"error on testing set: %7.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mte\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theanets/feedforward.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mvariables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         '''\n\u001b[1;32m--> 489\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[0m__call__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theanets/feedforward.pyc\u001b[0m in \u001b[0;36mfeed_forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/blas.pyc\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inp, out)\u001b[0m\n\u001b[0;32m   1610\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1611\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1612\u001b[1;33m             \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1613\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1614\u001b[0m             \u001b[1;31m# The error raised by numpy has no shape information, we mean to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import theanets\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "D = loadmat('data/ex3data1.mat')\n",
    "X, y = D['X'], D['y']\n",
    "\n",
    "\n",
    "#y=y.ravel() # y musi być wektorem, a nie macierzą (5000, 1)\n",
    "#y = y.reshape(y.shape[0],1)\n",
    "y[y == 10] = 0\n",
    "print X.shape, y.shape\n",
    "\n",
    "a_train, a_test, b_train, b_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "x = X[0]\n",
    "#b = b_train.ravel()\n",
    "#print a_train.shape[1]\n",
    "exp = theanets.Experiment(\n",
    "#    theanets.recurrent.Regressor,\n",
    "#     layers=(a_train.shape[1], \n",
    "#             10, \n",
    "#             10)\n",
    "#     )\n",
    "theanets.feedforward.Regressor,\n",
    "                    layers=(400,10,1),\n",
    "                    optimize='sgd',\n",
    "                    activation='tanh')\n",
    "\n",
    "print b_train\n",
    "\n",
    "for iters, (train, valid) in enumerate(exp.itertrain((a_train, b_train), optimize='sgd', \n",
    "                                                    learning_rate=0.1, momentum=0.1,\n",
    "                                                    patience=1)):\n",
    "        print iters\n",
    "        #print exp.network.predict(a_train).astype(int)\n",
    "        tr = 1.0 - accuracy_score(b_train, exp.network.predict(a_train).astype(int), normalize=False)\n",
    "        te = 1.0 - accuracy_score(b_test, exp.network.predict(a_test).astype(int), normalize=False)\n",
    "        print iters, \"error on training set: %7.4f\" % tr\n",
    "        print iters, \"error on testing set: %7.4f\" % te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytania analityczne / do dyskusji\n",
    "\n",
    "* Co się dzieje gdy zmienisz wielkość warstwy ukrytej na np. `10`? A jeśli na `2000`? \n",
    "* Jak wyglądają te wykresy dla modeli regresji i klasyfikacji? \n",
    "* Skąd takie zależności? \n",
    "* Czy potrafisz wydzielić jakieś sekcje w obserwowanych wykresach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "216 error on training set:  0.0312\n",
    "216 error on testing set:  0.0940 neurony 10 w warstwie ukrytej\n",
    "warstwa 200, strasznie dlugo liczy i jakby szybciej zbiega przy 60 iteracji mam juz 0.08 i  0.10 i na trenujacym wiekszy\n",
    "blad, ale mniejsza roznica wzgledem testujacego:\n",
    "216 error on training set:  0.0312\n",
    "216 error on testing set:  0.0896\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykładowe rezultaty\n",
    "\n",
    "\n",
    "#### Regresja 10 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/10reg.png\" width=\"600\">\n",
    "\n",
    "#### Klasyfikacja 10 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/10cla.png\" width=\"600\">\n",
    "\n",
    "#### Regresja 100 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/100reg.png\" width=\"600\">\n",
    "\n",
    "#### Klasyfikacja 100 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/100cla.png\" width=\"600\">\n",
    "\n",
    "#### Regresja 1000 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/1000reg.png\" width=\"600\">\n",
    "\n",
    "#### Klasyfikacja 1000 neuronów\n",
    "\n",
    "<img src=\"files/SN4_img/1000cla.png\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
